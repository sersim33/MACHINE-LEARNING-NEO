{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":3970170,"sourceType":"datasetVersion","datasetId":2356282}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T08:05:49.061820Z","iopub.execute_input":"2024-11-22T08:05:49.062137Z","iopub.status.idle":"2024-11-22T08:05:51.331988Z","shell.execute_reply.started":"2024-11-22T08:05:49.062097Z","shell.execute_reply":"2024-11-22T08:05:51.331135Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install --upgrade ultralytics \n!pip install --upgrade -U ray[tune]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T08:05:51.333206Z","iopub.execute_input":"2024-11-22T08:05:51.333692Z","iopub.status.idle":"2024-11-22T08:06:08.252116Z","shell.execute_reply.started":"2024-11-22T08:05:51.333652Z","shell.execute_reply":"2024-11-22T08:06:08.251188Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport os\nimport re\nimport glob\nimport random\nimport yaml\n\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Rectangle\nimport seaborn as sns\n\n# import IPython.display as display\nfrom PIL import Image\nimport cv2\n\nfrom ultralytics import YOLO\n\n%matplotlib inline\n\n! wandb disabled","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T08:06:08.253523Z","iopub.execute_input":"2024-11-22T08:06:08.253872Z","iopub.status.idle":"2024-11-22T08:06:12.576837Z","shell.execute_reply.started":"2024-11-22T08:06:08.253842Z","shell.execute_reply":"2024-11-22T08:06:12.575823Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!ls /kaggle/input/indoor-object-detection/\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T08:06:12.579686Z","iopub.execute_input":"2024-11-22T08:06:12.580449Z","iopub.status.idle":"2024-11-22T08:06:13.619855Z","shell.execute_reply.started":"2024-11-22T08:06:12.580416Z","shell.execute_reply":"2024-11-22T08:06:13.618918Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!ls /kaggle/input/indoor-object-detection/train/\n!ls /kaggle/input/indoor-object-detection/test/\n!ls /kaggle/input/indoor-object-detection/valid/\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T08:06:13.621347Z","iopub.execute_input":"2024-11-22T08:06:13.621663Z","iopub.status.idle":"2024-11-22T08:06:16.727614Z","shell.execute_reply.started":"2024-11-22T08:06:13.621635Z","shell.execute_reply":"2024-11-22T08:06:16.726679Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!find /kaggle/input/indoor-object-detection/train/images/ -type f \\( -iname \"*.jpg\" -o -iname \"*.png\" \\) | wc -l\n!find /kaggle/input/indoor-object-detection/test/images/ -type f \\( -iname \"*.jpg\" -o -iname \"*.png\" \\) | wc -l\n!find /kaggle/input/indoor-object-detection/valid/images/ -type f \\( -iname \"*.jpg\" -o -iname \"*.png\" \\) | wc -l\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T08:06:16.729276Z","iopub.execute_input":"2024-11-22T08:06:16.729696Z","iopub.status.idle":"2024-11-22T08:06:19.812909Z","shell.execute_reply.started":"2024-11-22T08:06:16.729654Z","shell.execute_reply":"2024-11-22T08:06:19.811762Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class CFG:\n    DEBUG = False # Set to True to make quick experiments\n    FRACTION = 0.05 if DEBUG else 1.0\n    SEED = 42\n\n    # classes\n    CLASSES = ['door', 'cabinetDoor', 'refrigeratorDoor', 'window',\n               'chair', 'table', 'cabinet',\n               'couch', 'openedDoor', 'pole']\n               \n    NUM_CLASSES_TO_TRAIN = len(CLASSES)\n\n    # training\n    EPOCHS = 3 if DEBUG else 70 # 100\n    BATCH_SIZE = 8\n    \n    BASE_MODEL = 'yolov9e' # yolov8n, yolov8s, yolov8m, yolov8l, yolov8x, yolov9c, yolov9e\n    BASE_MODEL_WEIGHTS = f'{BASE_MODEL}.pt'\n    EXP_NAME = f'ppe_css_{EPOCHS}_epochs'\n    \n    OPTIMIZER = 'auto' # SGD, Adam, Adamax, AdamW, NAdam, RAdam, RMSProp, auto\n    LR = 1e-3\n    LR_FACTOR = 0.01\n    WEIGHT_DECAY = 5e-4\n    DROPOUT = 0.0\n    PATIENCE = 20\n    PROFILE = False\n    LABEL_SMOOTHING = 0.0    \n\n    # paths\n    CUSTOM_DATASET_DIR = '/kaggle/input/indoor-object-detection/'\n    OUTPUT_DIR = '/kaggle/working/'\n   ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T08:06:19.814561Z","iopub.execute_input":"2024-11-22T08:06:19.814898Z","iopub.status.idle":"2024-11-22T08:06:19.821566Z","shell.execute_reply.started":"2024-11-22T08:06:19.814868Z","shell.execute_reply":"2024-11-22T08:06:19.820555Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dict_file = {\n    'train': os.path.join(CFG.CUSTOM_DATASET_DIR, 'train'),\n    'val': os.path.join(CFG.CUSTOM_DATASET_DIR, 'valid'),\n    'test': os.path.join(CFG.CUSTOM_DATASET_DIR, 'test'),\n    'nc': CFG.NUM_CLASSES_TO_TRAIN,\n    'names': CFG.CLASSES\n    }\n\nwith open(os.path.join(CFG.OUTPUT_DIR, 'data.yaml'), 'w+') as file:\n    yaml.dump(dict_file, file)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T08:06:19.822383Z","iopub.execute_input":"2024-11-22T08:06:19.822622Z","iopub.status.idle":"2024-11-22T08:06:19.833008Z","shell.execute_reply.started":"2024-11-22T08:06:19.822594Z","shell.execute_reply":"2024-11-22T08:06:19.832260Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"### read yaml file created\ndef read_yaml_file(file_path = CFG.CUSTOM_DATASET_DIR):\n    with open(file_path, 'r') as file:\n        try:\n            data = yaml.safe_load(file)\n            return data\n        except yaml.YAMLError as e:\n            print(\"Error reading YAML:\", e)\n            return None\n\n### print it with newlines\ndef print_yaml_data(data):\n    formatted_yaml = yaml.dump(data, default_style=False)\n    print(formatted_yaml)\n\nfile_path = os.path.join(CFG.OUTPUT_DIR, 'data.yaml')\nyaml_data = read_yaml_file(file_path)\n\nif yaml_data:\n    print_yaml_data(yaml_data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T08:06:19.833922Z","iopub.execute_input":"2024-11-22T08:06:19.834211Z","iopub.status.idle":"2024-11-22T08:06:19.846366Z","shell.execute_reply.started":"2024-11-22T08:06:19.834172Z","shell.execute_reply":"2024-11-22T08:06:19.845606Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom PIL import Image\nimport os\n\ndef display_image(image_path, print_info=True, hide_axis=False):\n    # Check if the image file exists\n    if not os.path.exists(image_path):\n        print(f\"Error: The file {image_path} does not exist.\")\n        return\n\n    # Open the image\n    img = Image.open(image_path)\n    \n    # Print image info if needed\n    if print_info:\n        print(f\"Image Path: {image_path}\")\n        print(f\"Image Size: {img.size}\")\n        print(f\"Image Mode: {img.mode}\")\n    \n    # Display the image\n    plt.imshow(img)\n    if hide_axis:\n        plt.axis('off')\n    plt.show()\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T08:06:19.847265Z","iopub.execute_input":"2024-11-22T08:06:19.847575Z","iopub.status.idle":"2024-11-22T08:06:19.859659Z","shell.execute_reply.started":"2024-11-22T08:06:19.847551Z","shell.execute_reply":"2024-11-22T08:06:19.858881Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Example usage\nexample_image_path = '/kaggle/input/indoor-object-detection/train/images/00bb60b91c5335b1.jpg'\ndisplay_image(example_image_path, print_info=True, hide_axis=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T08:06:19.860660Z","iopub.execute_input":"2024-11-22T08:06:19.860960Z","iopub.status.idle":"2024-11-22T08:06:20.261320Z","shell.execute_reply.started":"2024-11-22T08:06:19.860909Z","shell.execute_reply":"2024-11-22T08:06:20.260501Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot_random_images_from_folder(folder_path, num_images=10, seed=CFG.SEED):\n    \n    random.seed(seed)\n\n    # Get a list of image files in the folder\n    image_files = [f for f in os.listdir(folder_path) if f.endswith(('.jpg', '.png', '.jpeg', '.gif'))]\n\n    # Ensure that we have at least num_images files to choose from\n    if len(image_files) < num_images:\n        raise ValueError(\"Not enough images in the folder\")\n\n    # Randomly select num_images image files\n    selected_files = random.sample(image_files, num_images)\n\n    # Create a subplot grid\n    num_cols = 5\n    num_rows = (num_images + num_cols - 1) // num_cols\n    fig, axes = plt.subplots(num_rows, num_cols, figsize=(12, 8))\n\n    for i, file_name in enumerate(selected_files):\n        # Open and display the image using PIL\n        img = Image.open(os.path.join(folder_path, file_name))\n        \n        if num_rows == 1:\n            ax = axes[i % num_cols]\n        else:\n            ax = axes[i // num_cols, i % num_cols]\n        \n        ax.imshow(img)\n        ax.axis('off')\n        # ax.set_title(file_name)\n\n    # Remove empty subplots\n    for i in range(num_images, num_rows * num_cols):\n        if num_rows == 1:\n            fig.delaxes(axes[i % num_cols])\n        else:\n            fig.delaxes(axes[i // num_cols, i % num_cols])\n\n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T08:06:20.262582Z","iopub.execute_input":"2024-11-22T08:06:20.262950Z","iopub.status.idle":"2024-11-22T08:06:20.273111Z","shell.execute_reply.started":"2024-11-22T08:06:20.262912Z","shell.execute_reply":"2024-11-22T08:06:20.272275Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"folder_path = CFG.CUSTOM_DATASET_DIR + 'train/images/'\nplot_random_images_from_folder(folder_path, num_images=10, seed=CFG.SEED)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T08:06:20.276457Z","iopub.execute_input":"2024-11-22T08:06:20.276747Z","iopub.status.idle":"2024-11-22T08:06:21.520218Z","shell.execute_reply.started":"2024-11-22T08:06:20.276721Z","shell.execute_reply":"2024-11-22T08:06:21.519365Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Function to get image properties after resizing\ndef get_image_properties(image_path, new_size=(640, 640)):\n    # Read the image file\n    img = cv2.imread(image_path)\n\n    # Check if the image file is read successfully\n    if img is None:\n        raise ValueError(\"Could not read image file\")\n\n    # Resize the image to the new size\n    img_resized = cv2.resize(img, new_size)\n\n    # Get resized image properties\n    properties = {\n        \"width\": img_resized.shape[1],        # Width of resized image\n        \"height\": img_resized.shape[0],       # Height of resized image\n        \"channels\": img_resized.shape[2] if len(img_resized.shape) == 3 else 1,  # Number of channels (1 for grayscale, 3 for RGB)\n        \"dtype\": img_resized.dtype,           # Data type of the image\n    }\n\n    return properties, img_resized  # Return both properties and resized image\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T08:06:21.521479Z","iopub.execute_input":"2024-11-22T08:06:21.521845Z","iopub.status.idle":"2024-11-22T08:06:21.528636Z","shell.execute_reply.started":"2024-11-22T08:06:21.521808Z","shell.execute_reply":"2024-11-22T08:06:21.527734Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"img_properties, img_resized = get_image_properties(example_image_path, new_size=(640, 640))\nimg_properties","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T08:06:21.529777Z","iopub.execute_input":"2024-11-22T08:06:21.530059Z","iopub.status.idle":"2024-11-22T08:06:21.558152Z","shell.execute_reply.started":"2024-11-22T08:06:21.530034Z","shell.execute_reply":"2024-11-22T08:06:21.557429Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class_idx = {str(i): CFG.CLASSES[i] for i in range(CFG.NUM_CLASSES_TO_TRAIN)}\n\nclass_stat = {}\ndata_len = {}\nclass_info = []\n\nfor mode in ['train', 'valid', 'test']:\n    class_count = {CFG.CLASSES[i]: 0 for i in range(CFG.NUM_CLASSES_TO_TRAIN)}\n\n    path = os.path.join(CFG.CUSTOM_DATASET_DIR, mode, 'labels')\n\n    for file in os.listdir(path):\n        with open(os.path.join(path, file)) as f:\n            lines = f.readlines()\n\n            for cls in set([line[0] for line in lines]):\n                class_count[class_idx[cls]] += 1\n\n    data_len[mode] = len(os.listdir(path))\n    class_stat[mode] = class_count\n\n    class_info.append({'Mode': mode, **class_count, 'Data_Volume': data_len[mode]})\n\ndataset_stats_df = pd.DataFrame(class_info)\nwith pd.option_context('display.max_columns', None): \n    display(dataset_stats_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T08:06:21.575569Z","iopub.execute_input":"2024-11-22T08:06:21.575829Z","iopub.status.idle":"2024-11-22T08:06:22.287384Z","shell.execute_reply.started":"2024-11-22T08:06:21.575805Z","shell.execute_reply":"2024-11-22T08:06:22.286511Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create subplots with 1 row and 3 columns\nfig, axes = plt.subplots(1, 3, figsize=(15, 5))\n\n# Plot vertical bar plots for each mode in subplots\nfor i, mode in enumerate(['train', 'valid', 'test']):\n    sns.barplot(\n        data=dataset_stats_df[dataset_stats_df['Mode'] == mode].drop(columns='Mode'),\n        orient='v',\n        ax=axes[i],\n        palette='Set2'\n    )\n    \n    axes[i].set_title(f'{mode.capitalize()} Class Statistics')\n    axes[i].set_xlabel('Classes')\n    axes[i].set_ylabel('Count')\n    axes[i].tick_params(axis='x', rotation=90) \n\n    # Add annotations on top of each bar\n    for p in axes[i].patches:\n        axes[i].annotate(f\"{int(p.get_height())}\", (p.get_x() + p.get_width() / 2., p.get_height()),\n                         ha='center', va='center', fontsize=8, color='black', xytext=(0, 5),\n                         textcoords='offset points')\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T08:06:22.288362Z","iopub.execute_input":"2024-11-22T08:06:22.288647Z","iopub.status.idle":"2024-11-22T08:06:23.159210Z","shell.execute_reply.started":"2024-11-22T08:06:22.288620Z","shell.execute_reply":"2024-11-22T08:06:23.158268Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = YOLO(CFG.BASE_MODEL_WEIGHTS)\n\nresults = model.predict(\n    source = example_image_path,\n\n    classes = [0],\n    conf = 0.30,\n#     device = [0,1], # inference with dual GPU\n    device = None, # inference with CPU\n    imgsz = (img_properties['height'], img_properties['width']),\n\n    save = True,\n    save_txt = True,\n    save_conf = True,\n    exist_ok = True,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T08:06:23.160432Z","iopub.execute_input":"2024-11-22T08:06:23.160953Z","iopub.status.idle":"2024-11-22T08:06:25.131679Z","shell.execute_reply.started":"2024-11-22T08:06:23.160918Z","shell.execute_reply":"2024-11-22T08:06:25.130807Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"### check predictions with base model\nexample_image_inference_output = example_image_path.split('/')[-1]\ndisplay_image(f'runs/detect/predict/{example_image_inference_output}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T08:06:25.132913Z","iopub.execute_input":"2024-11-22T08:06:25.133845Z","iopub.status.idle":"2024-11-22T08:06:25.424301Z","shell.execute_reply.started":"2024-11-22T08:06:25.133800Z","shell.execute_reply":"2024-11-22T08:06:25.423436Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print('Model: ', CFG.BASE_MODEL_WEIGHTS)\nprint('Epochs: ', CFG.EPOCHS)\nprint('Batch: ', CFG.BATCH_SIZE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T08:06:25.425511Z","iopub.execute_input":"2024-11-22T08:06:25.425811Z","iopub.status.idle":"2024-11-22T08:06:25.430669Z","shell.execute_reply.started":"2024-11-22T08:06:25.425776Z","shell.execute_reply":"2024-11-22T08:06:25.429793Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"### Load pre-trained YOLO model\nmodel = YOLO(CFG.BASE_MODEL_WEIGHTS)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T08:06:25.431617Z","iopub.execute_input":"2024-11-22T08:06:25.431913Z","iopub.status.idle":"2024-11-22T08:06:25.927453Z","shell.execute_reply.started":"2024-11-22T08:06:25.431869Z","shell.execute_reply":"2024-11-22T08:06:25.926643Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nos.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n\nimport torch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T08:06:25.928465Z","iopub.execute_input":"2024-11-22T08:06:25.928737Z","iopub.status.idle":"2024-11-22T08:06:25.933013Z","shell.execute_reply.started":"2024-11-22T08:06:25.928710Z","shell.execute_reply":"2024-11-22T08:06:25.932155Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# %%time\n\n### train\nmodel.train(\n    data = os.path.join(CFG.OUTPUT_DIR, 'data.yaml'),\n\n    task = 'detect',\n\n    imgsz = (img_properties['height'], img_properties['width']),\n\n    epochs = CFG.EPOCHS,\n    batch = CFG.BATCH_SIZE,\n    optimizer = CFG.OPTIMIZER,\n    lr0 = CFG.LR,\n    lrf = CFG.LR_FACTOR,\n    weight_decay = CFG.WEIGHT_DECAY,\n    dropout = CFG.DROPOUT,\n    fraction = CFG.FRACTION,\n    patience = CFG.PATIENCE,\n    profile = CFG.PROFILE,\n    label_smoothing = CFG.LABEL_SMOOTHING,\n\n    name = f'{CFG.BASE_MODEL}_{CFG.EXP_NAME}',\n    seed = CFG.SEED,\n    \n    val = True,\n    amp = True,    \n    exist_ok = True,\n    resume = False,\n    device = [0], \n#     device = None, # CPU run\n    verbose = False,\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T08:07:39.239672Z","iopub.execute_input":"2024-11-22T08:07:39.240616Z","iopub.status.idle":"2024-11-22T10:50:59.240225Z","shell.execute_reply.started":"2024-11-22T08:07:39.240577Z","shell.execute_reply":"2024-11-22T10:50:59.239290Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Export the model\nmodel.export(\n    format = 'onnx', # openvino, onnx, engine, tflite\n    imgsz = (img_properties['height'], img_properties['width']),\n    half = False,\n    int8 = False,\n    simplify = False,\n    nms = False,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T11:04:12.889899Z","iopub.execute_input":"2024-11-22T11:04:12.890298Z","iopub.status.idle":"2024-11-22T11:04:29.338159Z","shell.execute_reply.started":"2024-11-22T11:04:12.890266Z","shell.execute_reply":"2024-11-22T11:04:29.337341Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"results_paths = [\n    i for i in\n    glob.glob(f'{CFG.OUTPUT_DIR}runs/detect/{CFG.BASE_MODEL}_{CFG.EXP_NAME}/*.png') +\n    glob.glob(f'{CFG.OUTPUT_DIR}runs/detect/{CFG.BASE_MODEL}_{CFG.EXP_NAME}/*.jpg')\n    if 'batch' not in i\n]\n\nresults_paths","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T11:05:09.506708Z","iopub.execute_input":"2024-11-22T11:05:09.507595Z","iopub.status.idle":"2024-11-22T11:05:09.514505Z","shell.execute_reply.started":"2024-11-22T11:05:09.507556Z","shell.execute_reply":"2024-11-22T11:05:09.513716Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for file in sorted(results_paths):\n    print(file)\n    display_image(file, print_info = False, hide_axis = True)\n    print('\\n')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T11:05:28.480804Z","iopub.execute_input":"2024-11-22T11:05:28.481509Z","iopub.status.idle":"2024-11-22T11:05:32.904011Z","shell.execute_reply.started":"2024-11-22T11:05:28.481475Z","shell.execute_reply":"2024-11-22T11:05:32.903064Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = pd.read_csv(f'{CFG.OUTPUT_DIR}runs/detect/{CFG.BASE_MODEL}_{CFG.EXP_NAME}/results.csv')\ndf = df.rename(columns=lambda x: x.replace(\" \", \"\"))\ndf.to_csv(f'{CFG.OUTPUT_DIR}training_log_df.csv', index=False)\ndf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T11:08:11.282960Z","iopub.execute_input":"2024-11-22T11:08:11.283593Z","iopub.status.idle":"2024-11-22T11:08:11.312077Z","shell.execute_reply.started":"2024-11-22T11:08:11.283558Z","shell.execute_reply":"2024-11-22T11:08:11.311200Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print('*'*50)\nprint('\\nBest Training Box loss: ', df['train/box_loss'].min(), ', on epoch: ', df['train/box_loss'].argmin() + 1, '\\n')\nprint('\\nBest Validation Box loss: ', df['val/box_loss'].min(), ', on epoch: ', df['val/box_loss'].argmin() + 1, '\\n')\n\nprint('='*50)\nprint('\\nBest Training Cls loss: ', df['train/cls_loss'].min(), ', on epoch: ', df['train/cls_loss'].argmin() + 1, '\\n')\nprint('\\nBest Validation Cls loss: ', df['val/cls_loss'].min(), ', on epoch: ', df['val/cls_loss'].argmin() + 1, '\\n')\n\nprint('='*50)\nprint('\\nBest Training DFL loss: ', df['train/dfl_loss'].min(), ', on epoch: ', df['train/dfl_loss'].argmin() + 1, '\\n')\nprint('\\nBest Validation DFL loss: ', df['val/dfl_loss'].min(), ', on epoch: ', df['val/dfl_loss'].argmin() + 1, '\\n')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T11:08:57.424678Z","iopub.execute_input":"2024-11-22T11:08:57.425402Z","iopub.status.idle":"2024-11-22T11:08:57.433849Z","shell.execute_reply.started":"2024-11-22T11:08:57.425359Z","shell.execute_reply":"2024-11-22T11:08:57.432816Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(10, 15), sharex=True)\n\n### Training and Validation box_loss\nax1.set_title('Box Loss')\nax1.plot(df['epoch'], df['train/box_loss'], label='Training box_loss', marker='o', linestyle='-')\nax1.plot(df['epoch'], df['val/box_loss'], label='Validation box_loss', marker='o', linestyle='-')\nax1.set_ylabel('Box Loss')\nax1.legend()\nax1.grid(True)\n\n### Training and Validation cls_loss\nax2.set_title('Cls Loss')\nax2.plot(df['epoch'], df['train/cls_loss'], label='Training cls_loss', marker='o', linestyle='-')\nax2.plot(df['epoch'], df['val/cls_loss'], label='Validation cls_loss', marker='o', linestyle='-')\nax2.set_ylabel('cls_loss')\nax2.legend()\nax2.grid(True)\n\n### Training and Validation dfl_loss\nax3.set_title('DFL Loss')\nax3.plot(df['epoch'], df['train/dfl_loss'], label='Training dfl_loss', marker='o', linestyle='-')\nax3.plot(df['epoch'], df['val/dfl_loss'], label='Validation dfl_loss', marker='o', linestyle='-')\nax3.set_xlabel('Epochs')\nax3.set_ylabel('dfl_loss')\nax3.legend()\nax3.grid(True)\n\nplt.suptitle('Training Metrics vs. Epochs')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T11:09:25.537636Z","iopub.execute_input":"2024-11-22T11:09:25.538017Z","iopub.status.idle":"2024-11-22T11:09:26.203229Z","shell.execute_reply.started":"2024-11-22T11:09:25.537984Z","shell.execute_reply":"2024-11-22T11:09:26.202182Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"validation_results_paths = [\n    i for i in\n    glob.glob(f'{CFG.OUTPUT_DIR}runs/detect/{CFG.BASE_MODEL}_{CFG.EXP_NAME}/*.png') +\n    glob.glob(f'{CFG.OUTPUT_DIR}runs/detect/{CFG.BASE_MODEL}_{CFG.EXP_NAME}/*.jpg')\n    if 'val_batch' in i\n]\n\nlen(validation_results_paths)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T11:10:22.339925Z","iopub.execute_input":"2024-11-22T11:10:22.340260Z","iopub.status.idle":"2024-11-22T11:10:22.347978Z","shell.execute_reply.started":"2024-11-22T11:10:22.340234Z","shell.execute_reply":"2024-11-22T11:10:22.347176Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if len(validation_results_paths) >= 1:\n    print(validation_results_paths[-1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T11:10:34.100500Z","iopub.execute_input":"2024-11-22T11:10:34.101338Z","iopub.status.idle":"2024-11-22T11:10:34.105962Z","shell.execute_reply.started":"2024-11-22T11:10:34.101300Z","shell.execute_reply":"2024-11-22T11:10:34.104919Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"### check predictions or labels from a random validation batch\nif len(validation_results_paths) >= 1:\n    val_img_path = random.choice(validation_results_paths)\n    print(val_img_path)\n    display_image(val_img_path, print_info = False, hide_axis = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T11:10:54.875419Z","iopub.execute_input":"2024-11-22T11:10:54.875808Z","iopub.status.idle":"2024-11-22T11:10:55.238803Z","shell.execute_reply.started":"2024-11-22T11:10:54.875775Z","shell.execute_reply":"2024-11-22T11:10:55.237918Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Висновок:\nМодель працює і показує кращі результати з кожною новою епохою.\nБачимо тенденції к зниженню  функції втрат як на навчальній, так і на валідаційній вибірках.\nАле F1 на рівні 45%, що каже про можливості для покращення моделі. \n\nІнші показники:\n•\tЗагальний mAP@0.5 ( при порозі IoU 0.5): 44%, - Mean Average Precision\n•\tmAP@0.5:0.95 (усереднений по різних порогах IoU): 26,3 %.\n\nДля класів openedDoor та pole, які є менш представленими у даних, ми маємо нижчі значення mAP@0.5, ніж для інших класів.\n\nЗ confusion matrix ми бачимо, що найчастіше не було розпізнано класи openedDoor, couch та pole.\n\nТакож ми  максимізуємо Precision при пороговому значені, близькому до 1, а Recall — до 0.\nХоча є місце для покращення. \n\n\nТренування  моделі потребує час та ресурси.\nАле якщо застосувати наступні кроки, то ми можемо покращити наші метрики:\n\nЗменьшити порог confidence (наприклад, до 0,25)\nЗбільшити кількість епох\nКоригувати (зменьшити)  швидкість навчання LR\nПідібрати інший OPTIMIZER (наприклад SGD, Adam)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}