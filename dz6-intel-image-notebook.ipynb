{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":269359,"sourceType":"datasetVersion","datasetId":111880}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-output":false,"execution":{"iopub.status.busy":"2024-11-18T13:08:06.102246Z","iopub.execute_input":"2024-11-18T13:08:06.102527Z","iopub.status.idle":"2024-11-18T13:08:30.201237Z","shell.execute_reply.started":"2024-11-18T13:08:06.102495Z","shell.execute_reply":"2024-11-18T13:08:30.200370Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, transforms, models\nfrom torch.utils.data import DataLoader, random_split\nfrom torchvision.utils import make_grid\nimport torch.nn.functional as F\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.metrics import confusion_matrix, f1_score\nimport seaborn as sns\n\nimport warnings\n# filter warnings\nwarnings.filterwarnings('ignore')\n\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2024-11-18T13:08:42.188442Z","iopub.execute_input":"2024-11-18T13:08:42.189294Z","iopub.status.idle":"2024-11-18T13:08:47.287578Z","shell.execute_reply.started":"2024-11-18T13:08:42.189254Z","shell.execute_reply":"2024-11-18T13:08:47.286590Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dir = '/kaggle/input/intel-image-classification/seg_train/seg_train'\ntest_dir = '/kaggle/input/intel-image-classification/seg_test/seg_test'\nval_dir = '/kaggle/input/intel-image-classification/seg_pred'","metadata":{"execution":{"iopub.status.busy":"2024-11-18T13:08:50.201310Z","iopub.execute_input":"2024-11-18T13:08:50.202041Z","iopub.status.idle":"2024-11-18T13:08:50.206125Z","shell.execute_reply.started":"2024-11-18T13:08:50.202001Z","shell.execute_reply":"2024-11-18T13:08:50.205135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize((120, 120)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])","metadata":{"execution":{"iopub.status.busy":"2024-11-18T13:08:52.779542Z","iopub.execute_input":"2024-11-18T13:08:52.780540Z","iopub.status.idle":"2024-11-18T13:08:52.786404Z","shell.execute_reply.started":"2024-11-18T13:08:52.780484Z","shell.execute_reply":"2024-11-18T13:08:52.785295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = datasets.ImageFolder(train_dir, transform=transform)\ntest_dataset = datasets.ImageFolder(test_dir, transform=transform)\nval_dataset = datasets.ImageFolder(val_dir, transform=transform)","metadata":{"execution":{"iopub.status.busy":"2024-11-18T13:08:55.168250Z","iopub.execute_input":"2024-11-18T13:08:55.169061Z","iopub.status.idle":"2024-11-18T13:09:00.254495Z","shell.execute_reply.started":"2024-11-18T13:08:55.169020Z","shell.execute_reply":"2024-11-18T13:09:00.253740Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32)\nval_loader = DataLoader(val_dataset, batch_size=32)","metadata":{"execution":{"iopub.status.busy":"2024-11-18T13:09:04.097126Z","iopub.execute_input":"2024-11-18T13:09:04.097501Z","iopub.status.idle":"2024-11-18T13:09:04.102878Z","shell.execute_reply.started":"2024-11-18T13:09:04.097459Z","shell.execute_reply":"2024-11-18T13:09:04.101902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Кількість класів: {len(train_dataset.classes)}\")\nprint(f\"Класи: {train_dataset.classes}\")\nprint(f\"Розмір тренувального набору: {len(train_dataset)}\")\nprint(f\"Розмір валідаційного набору: {len(val_dataset)}\")\nprint(f\"Розмір тестового набору: {len(test_dataset)}\")\n\n# Перевірка балансу класів у тренувальному наборі\nclass_counts = {class_name: 0 for class_name in train_dataset.classes}\nfor _, label in train_dataset.samples:\n    class_counts[train_dataset.classes[label]] += 1\n\nprint(\"\\nРозподіл класів у тренувальному наборі:\")\nfor class_name, count in class_counts.items():\n    print(f\"{class_name}: {count}\")","metadata":{"execution":{"iopub.status.busy":"2024-11-18T13:09:09.705337Z","iopub.execute_input":"2024-11-18T13:09:09.705722Z","iopub.status.idle":"2024-11-18T13:09:09.717860Z","shell.execute_reply.started":"2024-11-18T13:09:09.705668Z","shell.execute_reply":"2024-11-18T13:09:09.716826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time\nimport torch\nimport os\nfrom torch import nn, optim\nfrom tempfile import TemporaryDirectory\nfrom torch.utils.data import DataLoader\n\n# Додати списки для збереження значень втрат і точностей\ntrain_losses = []\ntest_losses = []\ntrain_accuracies = []\ntest_accuracies = []\n\n# Assuming `train_loader` and `val_loader` are already defined\ndef train_model(model, criterion, optimizer, num_epochs=4, train_loader=None, test_loader=None):\n    since = time.time()\n    best_model_wts = model.state_dict()\n    best_acc = 0.0\n\n    for epoch in range(num_epochs):\n        print(f'Epoch {epoch+1}/{num_epochs}')\n        print('-' * 10)\n\n        # Training phase\n        model.train()  # Set model to training mode\n        running_loss = 0.0\n        running_corrects = 0\n        for inputs, labels in train_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            optimizer.zero_grad()  # Zero the gradients\n\n            # Forward pass\n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)\n            loss = criterion(outputs, labels)\n\n            # Backward pass and optimization\n            loss.backward()\n            optimizer.step()\n\n            running_loss += loss.item() * inputs.size(0)\n            running_corrects += torch.sum(preds == labels.data)\n\n        epoch_loss = running_loss / len(train_loader.dataset)\n        epoch_acc = running_corrects.double() / len(train_loader.dataset)\n\n        # Зберегти втрати та точності для тренування\n        train_losses.append(epoch_loss)\n        train_accuracies.append(epoch_acc.item())\n\n        print(f'Training Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n\n        # Validation phase\n        model.eval()  # Set model to evaluation mode\n        running_loss = 0.0\n        running_corrects = 0\n        with torch.no_grad():  # No gradients needed for validation\n            for inputs, labels in test_loader:\n                inputs, labels = inputs.to(device), labels.to(device)\n\n                # Forward pass\n                outputs = model(inputs)\n                _, preds = torch.max(outputs, 1)\n                loss = criterion(outputs, labels)\n\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n\n        test_loss = running_loss / len(test_loader.dataset)\n        test_acc = running_corrects.double() / len(test_loader.dataset)\n\n        # Зберегти втрати та точності для валідації\n        test_losses.append(test_loss)\n        test_accuracies.append(test_acc.item())\n\n        print(f'Validation Loss: {test_loss:.4f} Acc: {test_acc:.4f}')\n\n        # Save the best model\n        if test_acc > best_acc:\n            best_acc = test_acc\n            best_model_wts = model.state_dict()\n\n    # Load best model weights\n    model.load_state_dict(best_model_wts)\n\n    time_elapsed = time.time() - since\n    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n    print(f'Best val Acc: {best_acc:.4f}')\n\n    return model\n","metadata":{"execution":{"iopub.status.busy":"2024-11-18T13:09:13.730573Z","iopub.execute_input":"2024-11-18T13:09:13.730956Z","iopub.status.idle":"2024-11-18T13:09:13.746428Z","shell.execute_reply.started":"2024-11-18T13:09:13.730920Z","shell.execute_reply":"2024-11-18T13:09:13.745541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_ft = models.resnet18(weights='IMAGENET1K_V1')\nnum_ftrs = model_ft.fc.in_features\n# Here the size of each output sample is set to 6.\n# Alternatively, it can be generalized to ``nn.Linear(num_ftrs, len(class_names))``.\nmodel_ft.fc = nn.Linear(num_ftrs, 6)\n\n# model_ft = model_ft.to(device)\n\ncriterion = nn.CrossEntropyLoss()\n\n# Observe that all parameters are being optimized\noptimizer_ft = optim.Adam(model_ft.parameters(), lr=1e-05)\n\n# Перенесення моделі на GPU, якщо доступно\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nmodel_ft = model_ft.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-11-18T13:09:17.946458Z","iopub.execute_input":"2024-11-18T13:09:17.947407Z","iopub.status.idle":"2024-11-18T13:09:18.790742Z","shell.execute_reply.started":"2024-11-18T13:09:17.947354Z","shell.execute_reply":"2024-11-18T13:09:18.789741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Example of calling the function\nmodel_ft = train_model(model_ft, criterion, optimizer_ft, num_epochs=4, train_loader=train_loader, test_loader=test_loader)","metadata":{"execution":{"iopub.status.busy":"2024-11-18T13:09:26.734567Z","iopub.execute_input":"2024-11-18T13:09:26.735348Z","iopub.status.idle":"2024-11-18T13:13:22.132504Z","shell.execute_reply.started":"2024-11-18T13:09:26.735307Z","shell.execute_reply":"2024-11-18T13:13:22.131523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\nimport matplotlib.pyplot as plt\n\ndef evaluate_model(model, test_loader):\n    model.eval()  # Переключити модель у режим оцінювання\n    all_preds = []\n    all_labels = []\n\n    with torch.no_grad():  # Без обчислення градієнтів\n        for inputs, labels in test_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n\n    # Обчислення точності та F1-міри\n    acc = accuracy_score(all_labels, all_preds)\n    f1 = f1_score(all_labels, all_preds, average='weighted')  # 'weighted' для урахування всіх класів\n    \n    # Показ точності та F1-міри\n    print(f'Accuracy: {acc:.4f}')\n    print(f'F1 Score: {f1:.4f}')\n\n    # Створення та відображення матриці плутанини\n    cm = confusion_matrix(all_labels, all_preds)\n    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=train_dataset.classes)\n    disp.plot(cmap=plt.cm.Blues)\n    plt.title('Confusion Matrix')\n    plt.show()\n\n# Виклик функції оцінки\nevaluate_model(model_ft, test_loader)","metadata":{"execution":{"iopub.status.busy":"2024-11-18T13:28:40.638879Z","iopub.execute_input":"2024-11-18T13:28:40.639760Z","iopub.status.idle":"2024-11-18T13:28:47.320298Z","shell.execute_reply.started":"2024-11-18T13:28:40.639717Z","shell.execute_reply":"2024-11-18T13:28:47.319404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef visualize_training_results(train_losses, test_losses, train_accuracies, test_accuracies, num_epochs):\n    \"\"\"\n    Функція для візуалізації втрат та точностей на тренувальних та валідаційних даних за епохи.\n\n    Параметри:\n    - train_losses: Список втрат на тренувальних даних за епохи\n    - test_losses: Список втрат на валідаційних даних за епохи\n    - train_accuracies: Список точностей на тренувальних даних за епохи\n    - test_accuracies: Список точностей на валідаційних даних за епохи\n    - num_epochs: Кількість епох у процесі тренування\n    \"\"\"\n\n    # Створення графіків для втрат\n    plt.figure(figsize=(12, 5))\n\n    # Графік втрат\n    plt.subplot(1, 2, 1)\n    plt.plot(range(1, num_epochs+1), train_losses, label='Train Loss')\n    plt.plot(range(1, num_epochs+1), test_losses, label='Validation Loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.title('Train vs Validation Loss')\n    plt.legend()\n\n    # Графік точностей\n    plt.subplot(1, 2, 2)\n    plt.plot(range(1, num_epochs+1), train_accuracies, label='Train Accuracy')\n    plt.plot(range(1, num_epochs+1), test_accuracies, label='Validation Accuracy')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.title('Train vs Validation Accuracy')\n    plt.legend()\n\n    # Відображення графіків\n    plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-11-18T13:29:56.017036Z","iopub.execute_input":"2024-11-18T13:29:56.017419Z","iopub.status.idle":"2024-11-18T13:29:56.026748Z","shell.execute_reply.started":"2024-11-18T13:29:56.017382Z","shell.execute_reply":"2024-11-18T13:29:56.025747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_training_results(train_losses, test_losses, train_accuracies, test_accuracies, num_epochs)","metadata":{"execution":{"iopub.status.busy":"2024-11-18T13:30:00.773870Z","iopub.execute_input":"2024-11-18T13:30:00.774236Z","iopub.status.idle":"2024-11-18T13:30:01.284008Z","shell.execute_reply.started":"2024-11-18T13:30:00.774200Z","shell.execute_reply":"2024-11-18T13:30:01.282958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport torch\nimport numpy as np\n\ndef visualize_predictions(model, dataloader, class_names, num_images=5):\n    \"\"\"\n    Функція для візуалізації передбачень моделі.\n    \n    Параметри:\n    - model: модель для передбачень\n    - dataloader: dataloader для тестових чи валідаційних даних\n    - class_names: список імен класів для декодування передбачень\n    - num_images: кількість зображень для візуалізації\n    \"\"\"\n    model.eval()  # Перевести модель в режим оцінки\n    images_so_far = 0\n    rows = (num_images // 2) + (num_images % 2)  # Розраховуємо кількість рядків для сітки\n    fig = plt.figure(figsize=(12, 3 * rows))  # Збільшено висоту фігури для кращої візуалізації\n\n    with torch.no_grad():  # Вимкнути градієнти для валідації\n        for inputs, labels in dataloader:\n            inputs, labels = inputs.to(device), labels.to(device)  # Переміщуємо на GPU, якщо є\n\n            outputs = model(inputs)  # Отримуємо передбачення\n            _, preds = torch.max(outputs, 1)  # Отримуємо передбачений клас для кожного зображення\n\n            for i in range(inputs.size(0)):\n                images_so_far += 1\n                ax = plt.subplot(rows, 2, images_so_far)  # Налаштовуємо підписи для сітки\n                ax.axis('off')\n                ax.set_title(f'Pred: {class_names[preds[i]]} / True: {class_names[labels[i]]}')\n\n                # Перетворення тензора в зображення для відображення\n                img = inputs.cpu().data[i].numpy().transpose((1, 2, 0))\n                img = np.clip(img, 0, 1)\n                ax.imshow(img)\n\n                if images_so_far == num_images:\n                    plt.tight_layout()\n                    plt.show()\n                    return  # Вивести тільки задану кількість зображень\n\n","metadata":{"execution":{"iopub.status.busy":"2024-11-18T13:30:05.262275Z","iopub.execute_input":"2024-11-18T13:30:05.263001Z","iopub.status.idle":"2024-11-18T13:30:05.273647Z","shell.execute_reply.started":"2024-11-18T13:30:05.262964Z","shell.execute_reply":"2024-11-18T13:30:05.272672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Приклад виклику\nvisualize_predictions(model_ft, test_loader, train_dataset.classes, num_images=6)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-18T13:30:09.286847Z","iopub.execute_input":"2024-11-18T13:30:09.287192Z","iopub.status.idle":"2024-11-18T13:30:10.305048Z","shell.execute_reply.started":"2024-11-18T13:30:09.287161Z","shell.execute_reply":"2024-11-18T13:30:10.304002Z"},"trusted":true},"execution_count":null,"outputs":[]}]}